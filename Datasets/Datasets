### Datasets
We're going to be using the Indiana University X-Ray dataset, as it has full reports, from which we can extract full feature lists from the images, as well as being a
reasonably sized dataset:
https://www.kaggle.com/raddar/chest-xrays-indiana-university

That dataset has already been normalized, and converted from DICOM to PNG, so I've just written a quick script to alter the images to 256 x 256 so they can be consistently 
entered into a neural network - link to the 256 x 256 converted dataset:
https://drive.google.com/drive/folders/11R2TRqwPmrlEpBgk0ur0CHdVpR32o_ez?usp=sharing


There are several other options for datasets - 

CheXpert:
https://stanfordmlgroup.github.io/competitions/chexpert/

NIH Chest X-Ray dataset:
https://www.kaggle.com/nih-chest-xrays/data

VinBigData Chest X-Ray Abnormality Dataset
https://www.kaggle.com/c/vinbigdata-chest-xray-abnormalities-detection

VinBigData Resized:
https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
(scripts to process the DICOM images to PNG, while resizing to a number of different sizes)

For this specific problem, and as a simple example, these are a little too large (the first two are >100,000 images each), and the VinBigData X-ray dataset only has 
1 of 14 potential features highlighted for each image, which is great for the problem they're working on specifically (using CV to put bounding boxes around those 1/14 things), 
but not great to write full radiology reports for each image.
